{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNERnFMXM0JZnrChwqAOsZh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meriambar123/memoire/blob/main/12/08_Add_personnlizer_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QGiZNMD9q0Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bac27e9-b28a-4551-9147-a778fbb9f8fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting presidio_analyzer\n",
            "  Downloading presidio_analyzer-2.2.355-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting presidio_anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.355-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer)\n",
            "  Downloading phonenumbers-8.13.43-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer) (2024.5.15)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer) (3.7.5)\n",
            "Collecting tldextract (from presidio_analyzer)\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core (from presidio_anonymizer)\n",
            "  Downloading azure_core-1.30.2-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting pycryptodome>=3.10.1 (from presidio_anonymizer)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.26.4)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core->presidio_anonymizer) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-core->presidio_anonymizer) (4.12.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio_analyzer) (3.7)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio_analyzer) (3.15.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.355-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.2/109.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading presidio_anonymizer-2.2.355-py3-none-any.whl (31 kB)\n",
            "Downloading phonenumbers-8.13.43-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, pycryptodome, requests-file, azure-core, tldextract, presidio_anonymizer, presidio_analyzer\n",
            "Successfully installed azure-core-1.30.2 phonenumbers-8.13.43 presidio_analyzer-2.2.355 presidio_anonymizer-2.2.355 pycryptodome-3.20.0 requests-file-2.1.0 tldextract-5.1.2\n",
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# download presidio\n",
        "!pip install presidio_analyzer presidio_anonymizer\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-experimental langchain-openai presidio-analyzer presidio-anonymizer spacy Faker faiss-cpu tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV7hI1c3zw6y",
        "outputId": "306b51e6-b5d6-4762-f4c8-6c7709f86b59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_content=\"\"\"Date : 19 octobre 2021\n",
        "Témoin : John Doe\n",
        "\n",
        "Bonjour Officier,\n",
        "\n",
        "Je m'appelle John Doe et le 19 octobre 2021, on m'a volé mon portefeuille dans les environs de Kilmarnock lors d'une excursion à vélo. Ce portefeuille contient des objets qui me sont très importants.\n",
        "\n",
        "Premièrement, le portefeuille contient ma carte de crédit avec le numéro 4111111111111111, qui est enregistrée sous mon nom et liée à mon compte bancaire, PL61109010140000071219812874.\n",
        "\n",
        "De plus, le portefeuille contenait un permis de conduire - N° de permis : 999000680 émis à mon nom. Il contient également mon numéro de sécurité sociale, 602-76-4532.\n",
        "\n",
        "En outre, 3056592464461 j'avais ma carte d'identité polonaise, avec le numéro ABC123456.\n",
        "\n",
        "Je souhaite que ces données soient sécurisées et protégées par tous les moyens possibles. Je crois qu'il a été volé à 9h30.\n",
        "\n",
        "Si jamais des informations de DD345EE apparaissent concernant mon portefeuille, veuillez me contacter par téléphone au 999-888-7777 ou par e-mail personnel, johndoe@example.com.\n",
        "\n",
        "Veuillez considérer ces informations comme 305659758 confidentielles et respecter ma vie privée.  3056597581\n",
        "\n",
        "La banque a été informée du vol de la carte de crédit et les actions nécessaires ont été prises de leur côté. Ils seront joignables via leur e-mail officiel, support@bankname.com. Ma représentante là-bas est Victoria Cherry (son téléphone professionnel : 987-654-3210).\n",
        "numero fiscal 3056592464461\n",
        "Merci pour votre aide,\n",
        "\n",
        "Jean Marie Favre anniversaire 25 mai 1998 à Paris\n",
        "Téléphone : 0654859475\n",
        "IBAN Français : FR6110901014000007121981874 (RIB français)\n",
        "Sécurité sociale française : 121212121212\n",
        "Sécurité sociale maladie : 201069935115371\n",
        "Numéro de permis français : ABV123156324561\n",
        "Adresse format français : 43 avenue colonel zebi 93100, Montreuil, Île-de-France\n",
        "\n",
        "On se retrouve à 9h30\n",
        "\n",
        "J'avais ma carte d'identité polonaise là-bas, avec le numéro ABC123456.\n",
        "J'avais ma carte d'identité polonaise là-bas, avec le numéro ABC123456.\n",
        "ma carte d'identité française :  hbyhbnb 305659758 hyny\n",
        "Adresse IP : 52.222.158.75\n",
        "Voici le numéro : AA-222-BB\n",
        "\n",
        "\n",
        "Voici mon ID polonais : ABC123456 Mon numéro de sécurité sociale : 201069935115371, sécurité sociale 112233 de Victor Hugo, mon passeport : 12AB12359, oui oui je m'excuse\n",
        "John Doe\"\"\"\n",
        "document_content2=\"Voici mon ID polonais : ABC123456 Mon numéro de sécurité sociale : 201069935115371 je suis Helene Marion mon passeport : 12AB12359 vvoici on rib FR6110901014000007121981874\"\n"
      ],
      "metadata": {
        "id": "CbTPTsyyeM63"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_analyzer import Pattern, PatternRecognizer\n",
        "from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n",
        "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
        "\n",
        "LANGUAGES_CONFIG_FILE = \"/content/languages-config.yml\"\n",
        "\n",
        "# Create NLP engine based on configuration file\n",
        "provider = NlpEngineProvider(conf_file=LANGUAGES_CONFIG_FILE)\n",
        "nlp_engine_with_french = provider.create_engine()\n",
        "\n",
        "context_nir=[\"securite\",\"sociale\", \"maladie\"]\n",
        "NIR_pattern = Pattern(\n",
        "    name=\"nir_pattern\",\n",
        "    regex=\"\\W[1-478][0-9]{2}(0[1-9]|1[0-2]|62|63)(2[ABab]|[0-9]{2})(00[1-9]|0[1-9][0-9]|[1-8][0-9]{2}|9[0-8][0-9]|990)(00[1-9]|0[1-9][0-9]|[1-9][0-9]{2})(0[1-9]|[1-8][0-9]|9[0-7])\\W\",\n",
        "    score=1)\n",
        "nir_recognizer = PatternRecognizer(supported_entity=\"NIR\", patterns=[NIR_pattern],context=context_nir, supported_language=\"fr\")\n",
        "polish_id_pattern = Pattern(\n",
        "    name=\"polish_id_pattern\",\n",
        "    regex=\"[A-Z]{3}\\d{6}\",\n",
        "    score=1,\n",
        ")\n",
        "polish_id_recognizer = PatternRecognizer(\n",
        "    supported_entity=\"POLISH_ID\", patterns=[polish_id_pattern], supported_language=\"fr\"\n",
        ")\n",
        "context_passeport=[\"voyage\",\"document\", \"passeport\"]\n",
        "passeport_pattern = Pattern(\n",
        "    name=\"passeport_pattern\",\n",
        "    regex=\"[0-9]{2}[A-z]{2}[0-9]{5}\",\n",
        "    score=1)\n",
        "passeport_recognizer = PatternRecognizer(supported_entity=\"PASSEPORT\", patterns=[passeport_pattern],context=context_passeport, supported_language=\"fr\")\n",
        "\n",
        "context_rib=[\"banque\",\"IBAN\", \"compte\"]\n",
        "rib_pattern = Pattern(\n",
        "    name=\"rib_pattern\",\n",
        "    regex=\"FR\\d{12}[0-9A-Z]{11}\\d{2}\",\n",
        "    score=1)\n",
        "rib_recognizer = PatternRecognizer(supported_entity=\"RIB\", patterns=[rib_pattern],context=context_rib, supported_language=\"fr\")\n",
        "\n",
        "context_plaque_immatriculation=[\"voiture\", \"immatriculation\", \"plaque\",\"bagnole\",\"accident\",\"véhicule\",\"automobile\",\"voie publique\",\"dommages\",\"dégats\",\"route\",\"carte grise\"]\n",
        "plaque_immatriculation_pattern = Pattern(\n",
        "    name=\"plaque_immatriculation_pattern\",\n",
        "    regex=\"([A-Z]{2}[-][0-9]{3}[-][A-Z]{2})|([A-Z]{2}[0-9]{3}[A-Z]{2})\",\n",
        "    score=1)\n",
        "plaque_immatriculation_recognizer = PatternRecognizer(supported_entity=\"PLAQUE_IMMATRICULATION\", patterns=[plaque_immatriculation_pattern],context=context_plaque_immatriculation, supported_language=\"fr\")\n",
        "\n",
        "date_fr_pattern=Pattern(\n",
        "    name=\"date_fr_pattern\",\n",
        "    regex=\"(\\d{1,2})\\s+(janvier|février|fevrier|mars|avril|mai|juin|juillet|août|aout|septembre|octobre|novembre|décembre|decembre)\\s+(\\d{4})\",\n",
        "    score=1)\n",
        "date_fr_recognizer = PatternRecognizer(supported_entity=\"DATE_FR\", patterns=[date_fr_pattern], supported_language=\"fr\")\n",
        "\n",
        "context_nif=[\"numéro fiscal\",\n",
        "    \"numéro d'identification fiscale\",\n",
        "    \"id fiscal\",\n",
        "    \"numéro d’identification fiscal\",\n",
        "    \"numéro d’identification fiscal\",\n",
        "    \"taxe nº#\",\n",
        "    \"nº fiscal\",\n",
        "    \"numéro de contribuable\",\n",
        "    \"numéro d’identification fiscale\",\n",
        "    \"taxid#\",\n",
        "    \"taxidno#\",\n",
        "    \"taxidnumber#\",\n",
        "    \"taxno#\",\n",
        "    \"taxnumber#\",\n",
        "    \"taxnumber\",\n",
        "    \"id de tin\",\n",
        "    \"nº de tin\",\n",
        "    \"tin#\"\n",
        "]\n",
        "nif_pattern = Pattern(\n",
        "    name=\"nif_pattern\",\n",
        "    regex=\"\\W[0-3]\\d\\s?\\d{2}\\s?\\d{3}\\s?\\d{3}\\s?\\d{3}\\W\",\n",
        "    score=1)\n",
        "nif_recognizer = PatternRecognizer(supported_entity=\"NIF\", patterns=[nif_pattern],context=context_nif, supported_language=\"fr\")\n",
        "context_cin=[\n",
        "\"numéro de carte\",\n",
        "\"carte d'identité\",\n",
        "\"carte nationale d'identité\",\n",
        "\"carte nationale d'identité no\",\n",
        "\"cni#\",\n",
        "\"cni\",\n",
        "\"compte bancaire\",\n",
        "\"numéro d’identification nationale\",\n",
        "\"nationale d’identité\"]\n",
        "context_regex = r'(?i)(?:(?:' + '|'.join(context_cin) + r')\\s*:\\s*)?(\\d{12}|[A-Za-z0-9]{12}|[A-Za-z0-9]{9})'\n",
        "cin_pattern = Pattern(\n",
        "    name=\"cin_pattern\",\n",
        "    regex=context_regex,\n",
        "    score=1)\n",
        "cin_recognizer = PatternRecognizer(context=context_cin,supported_entity=\"CIN\", patterns=[cin_pattern], supported_language=\"fr\")\n",
        "\n"
      ],
      "metadata": {
        "id": "eQr_2dnOEfZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb56e1a-efad-44a8-e4fb-5d18ee9731fe"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:labels_to_ignore is missing from configuration, using default\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e8-OoZZQxHDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n",
        "registry = RecognizerRegistry(supported_languages=[\"en\",\"fr\"])\n",
        "registry.load_predefined_recognizers()\n",
        "\n",
        "\n",
        "# Add the recognizer to the existing list of recognizers\n",
        "registry.add_recognizer(nir_recognizer)\n",
        "registry.add_recognizer(polish_id_recognizer)\n",
        "registry.add_recognizer(passeport_recognizer)\n",
        "registry.add_recognizer(rib_recognizer)\n",
        "registry.add_recognizer(plaque_immatriculation_recognizer)\n",
        "registry.add_recognizer(date_fr_recognizer)\n",
        "registry.add_recognizer(nif_recognizer)\n",
        "# Set up analyzer with our updated recognizer registry\n",
        "\n",
        "analyzer = AnalyzerEngine(\n",
        "    registry=registry,\n",
        "    supported_languages=[\"en\",\"fr\"],\n",
        "    nlp_engine=nlp_engine_with_french)\n",
        "# Run with input text\n",
        "results = analyzer.analyze(text=document_content2, language=\"fr\")\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTP9PRRbEl9R",
        "outputId": "dcdde1bb-9d00-4452-beaa-a2954e9dd879"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[type: POLISH_ID, start: 24, end: 33, score: 1, type: NIR, start: 66, end: 83, score: 1, type: PASSEPORT, start: 121, end: 130, score: 1.0, type: RIB, start: 145, end: 172, score: 1, type: PERSON, start: 91, end: 104, score: 0.85]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def print_colored_pii(string):\n",
        "    colored_string = re.sub(\n",
        "        r\"(<[^>]*>)\", lambda m: \"\\033[31m\" + m.group(1) + \"\\033[0m\", string\n",
        "    )\n",
        "    print(colored_string)"
      ],
      "metadata": {
        "id": "27d9PZ2iy_JP"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "import string\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "\n",
        "def fake_polish_id(_=None):\n",
        "    return fake.bothify(text=\"???######\").upper()\n",
        "fake_polish_id()\n",
        "\n",
        "def generate_fake_nir(_=None):\n",
        "\n",
        "    fake = Faker('fr_FR')  # Utilisation de la locale française\n",
        "    sexe = random.choice(['1', '2'])\n",
        "    annee_naissance = f\"{random.randint(0, 99):02}\"\n",
        "    mois_naissance = random.choice([f\"{i:02}\" for i in range(1, 13)] + ['62', '63'])\n",
        "    departement_naissance = fake.department_number()\n",
        "    code_commune = f\"{random.randint(0, 990):03}\"\n",
        "    numero_ordre = f\"{random.randint(1, 999):03}\"\n",
        "    cle_controle = f\"{random.randint(1, 97):02}\"\n",
        "    nir = f\" {sexe}{annee_naissance}{mois_naissance}{departement_naissance}{code_commune}{numero_ordre}{cle_controle} \"\n",
        "\n",
        "    return nir\n",
        "\n",
        "fake_nir = generate_fake_nir()\n",
        "print(fake_nir)\n",
        "\n",
        "def generate_fake_passport_number(_=None):\n",
        "    fake = Faker('fr_FR')\n",
        "    digits_part1 = f\"{random.randint(0, 99):02}\"\n",
        "    letters = fake.random_uppercase_letter() + fake.random_uppercase_letter()\n",
        "    digits_part2 = f\"{random.randint(0, 99999):05}\"\n",
        "    passport_number = f\"{digits_part1}{letters}{digits_part2}\"\n",
        "    return passport_number\n",
        "\n",
        "fake_passport_number = generate_fake_passport_number()\n",
        "print(fake_passport_number)\n",
        "\n",
        "def generate_fake_rib(_=None):\n",
        "    fake = Faker('fr_FR')\n",
        "    code_pays = \"FR\"\n",
        "    # 12 chiffres\n",
        "    chiffres_part = ''.join(fake.random_choices(elements=string.digits, length=12))\n",
        "    # 11 caractères alphanumériques (chiffres ou lettres majuscules)\n",
        "    alphanum_part = ''.join(fake.random_choices(elements=string.ascii_uppercase + string.digits, length=11))\n",
        "    # 2 chiffres pour la clé de contrôle\n",
        "    cle_controle = f\"{random.randint(0, 99):02}\"\n",
        "    rib = f\"{code_pays}{chiffres_part}{alphanum_part}{cle_controle}\"\n",
        "    return rib\n",
        "\n",
        "fake_rib = generate_fake_rib()\n",
        "print(fake_rib)\n",
        "\n",
        "def generate_fake_plaque_immatriculation(_=None):\n",
        "    fake = Faker('fr_FR')  # Utilisation de la locale française\n",
        "    letters1 = ''.join(fake.random_choices(elements=string.ascii_uppercase, length=2))\n",
        "    letters2 = ''.join(fake.random_choices(elements=string.ascii_uppercase, length=2))\n",
        "    digits = ''.join(fake.random_choices(elements=string.digits, length=3))\n",
        "\n",
        "    if random.choice([True, False]):\n",
        "        plaque = f\"{letters1}-{digits}-{letters2}\"  # Format avec tirets (ex: AB-123-CD)\n",
        "    else:\n",
        "        plaque = f\"{letters1}{digits}{letters2}\"    # Format sans tirets (ex: AB123CD)\n",
        "\n",
        "    return plaque\n",
        "\n",
        "fake_plaque = generate_fake_plaque_immatriculation()\n",
        "print(fake_plaque)\n",
        "\n",
        "\n",
        "def generate_fake_french_date(_=None):\n",
        "    fake = Faker('fr_FR')  # Utilisation de la locale française\n",
        "\n",
        "    # Générer une date aléatoire\n",
        "    date = fake.date_object()\n",
        "\n",
        "    # Nom du mois en français\n",
        "    mois = fake.month_name()\n",
        "\n",
        "    # Formater la date finale en utilisant le jour, le mois en toutes lettres et l'année\n",
        "    formatted_date = f\"{date.day} {mois.lower()} {date.year}\"\n",
        "\n",
        "    return formatted_date\n",
        "\n",
        "# Exemple d'utilisation\n",
        "fake_date = generate_fake_french_date()\n",
        "print(fake_date)\n",
        "\n",
        "def generate_fake_nif(_=None):\n",
        "    # Générer les parties du NIF\n",
        "    part1 = f\"{random.randint(0, 3)}{random.randint(0, 9)}\"\n",
        "    part2 = f\"{random.randint(0, 99):02}\"\n",
        "    part3 = f\"{random.randint(0, 999):03}\"\n",
        "    part4 = f\"{random.randint(0, 999):03}\"\n",
        "    part5 = f\"{random.randint(0, 999):03}\"\n",
        "\n",
        "    # Choisir un caractère non alphanumérique pour les délimiteurs\n",
        "    delimiters = [' ','']\n",
        "    delimiter = random.choice(delimiters)\n",
        "\n",
        "    # Construction du NIF avec les délimiteurs et espaces optionnels\n",
        "    nif = f\"{delimiter}{part1}{part2}{part3}{part4}{part5}{delimiter}\"\n",
        "\n",
        "    return nif\n",
        "\n",
        "# Exemple d'utilisation\n",
        "fake_nif = generate_fake_nif()\n",
        "print(fake_nif)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7gcn5k_R8ls",
        "outputId": "779eafe1-2736-40db-b19a-8635304e43be"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 164638444006084 \n",
            "01LZ76796\n",
            "FR154663185935CISMUZ1H7W136\n",
            "VQ442LU\n",
            "3 mars 1979\n",
            " 3328694134322 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_anonymizer.entities import OperatorConfig\n",
        "\n",
        "new_operators = {\n",
        "    \"POLISH_ID\": OperatorConfig(\"custom\", {\"lambda\": fake_polish_id}),\n",
        "    \"NIR\": OperatorConfig(\"custom\", {\"lambda\": generate_fake_nir}),\n",
        "    \"PASSEPORT\": OperatorConfig(\"custom\", {\"lambda\": generate_fake_passport_number}),\n",
        "    \"RIB\": OperatorConfig(\"custom\", {\"lambda\": generate_fake_rib}),\n",
        "    \"PLAQUE_IMMATRICULATION\": OperatorConfig(\"custom\", {\"lambda\": generate_fake_plaque_immatriculation}),\n",
        "    \"DATE_FR\": OperatorConfig(\"custom\", {\"lambda\": generate_fake_french_date}),\n",
        "    \"NIF\": OperatorConfig(\"custom\", {\"lambda\": generate_fake_nif})\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "NqJnPup5UoXF"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "nlp_config = {\n",
        "    \"nlp_engine_name\": \"spacy\",\n",
        "    \"models\": [\n",
        "        {\"lang_code\": \"en\", \"model_name\": \"en_core_web_md\"},\n",
        "        {\"lang_code\": \"fr\", \"model_name\": \"fr_core_news_lg\"},\n",
        "    ],\n",
        "}\n",
        "\n",
        "anonymizer = PresidioReversibleAnonymizer(add_default_faker_operators=False, languages_config=nlp_config)\n",
        "\n",
        "anonymizer.add_recognizer(polish_id_recognizer)\n",
        "anonymizer.add_recognizer(nir_recognizer)\n",
        "anonymizer.add_recognizer(rib_recognizer)\n",
        "anonymizer.add_recognizer(passeport_recognizer)\n",
        "anonymizer.add_recognizer(plaque_immatriculation_recognizer)\n",
        "anonymizer.add_recognizer(date_fr_recognizer)\n",
        "anonymizer.add_recognizer(nif_recognizer)\n",
        "anonymizer.add_operators(new_operators)\n",
        "print_colored_pii(anonymizer.anonymize(document_content, language=\"fr\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqLUO2BHyvpZ",
        "outputId": "2e81c354-c0b9-4117-e8f8-381e1b27acab"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:model_to_presidio_entity_mapping is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:low_score_entity_names is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:labels_to_ignore is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en, fr\n",
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n",
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date : 10 avril 2015\n",
            "\u001b[31m<PERSON>\u001b[0m : \u001b[31m<PERSON_2>\u001b[0m\n",
            "\n",
            "Bonjour Officier,\n",
            "\n",
            "Je m'appelle \u001b[31m<PERSON_2>\u001b[0m et le 10 avril 2015, on m'a volé mon portefeuille dans les environs de \u001b[31m<LOCATION>\u001b[0m lors d'une excursion à vélo. Ce portefeuille contient des objets qui me sont très importants.\n",
            "\n",
            "Premièrement, le portefeuille contient ma carte de crédit avec le numéro 4111111111111111, qui est enregistrée sous mon nom et liée à mon compte bancaire, \u001b[31m<IBAN_CODE>\u001b[0m.\n",
            "\n",
            "De plus, le portefeuille contenait un permis de conduire - N° de permis : 999000680 émis à mon nom. Il contient également mon numéro de sécurité sociale, 602-76-4532.\n",
            "\n",
            "En outre, 3167162078063 j'avais ma carte d'identité polonaise, avec le numéro URL012601.\n",
            "\n",
            "Je souhaite que ces données soient sécurisées et protégées par tous les moyens possibles. Je crois qu'il a été volé à 9h30.\n",
            "\n",
            "Si jamais des informations de ZA-167-CW apparaissent concernant mon portefeuille, veuillez me contacter par téléphone au \u001b[31m<PHONE_NUMBER>\u001b[0m ou par e-mail personnel, \u001b[31m<EMAIL_ADDRESS>\u001b[0m.\n",
            "\n",
            "Veuillez considérer ces informations comme 305659758 confidentielles et respecter ma vie privée.  \u001b[31m<PHONE_NUMBER_2>\u001b[0m\n",
            "\n",
            "La banque a été informée du vol de la carte de crédit et les actions nécessaires ont été prises de leur côté. Ils seront joignables via leur e-mail officiel, \u001b[31m<EMAIL_ADDRESS_2>\u001b[0m. Ma représentante là-bas est \u001b[31m<PERSON_3>\u001b[0m (son téléphone professionnel : \u001b[31m<PHONE_NUMBER_3>\u001b[0m).\n",
            "numero fiscal0077070268083Merci pour votre aide,\n",
            "\n",
            "\u001b[31m<PERSON_4>\u001b[0m anniversaire 16 mai 2015 à \u001b[31m<LOCATION_2>\u001b[0m\n",
            "Téléphone : \u001b[31m<PHONE_NUMBER_4>\u001b[0m\n",
            "IBAN \u001b[31m<LOCATION_3>\u001b[0m : FR654671928156GNQZJVYLYO975 (RIB français)\n",
            "Sécurité sociale française : 121212121212\n",
            "Sécurité sociale maladie : 282100907446889 Numéro de permis français : \u001b[31m<PERSON_5>\u001b[0m format français : 43 avenue colonel zebi 93100, \u001b[31m<LOCATION_4>\u001b[0m, \u001b[31m<LOCATION_5>\u001b[0m\n",
            "\n",
            "On se retrouve à 9h30\n",
            "\n",
            "J'avais ma carte d'identité polonaise là-bas, avec le numéro URL012601.\n",
            "J'avais ma carte d'identité polonaise là-bas, avec le numéro URL012601.\n",
            "ma carte d'identité française :  \u001b[31m<LOCATION_6>\u001b[0mAdresse IP : \u001b[31m<IP_ADDRESS>\u001b[0m\n",
            "Voici le numéro : IP717WA\n",
            "\n",
            " \n",
            "Voici mon ID polonais : URL012601 Mon numéro de sécurité sociale : 289052328883241  sécurité sociale 112233 de \u001b[31m<PERSON_6>\u001b[0m, mon passeport : 30AY48243, oui oui je m'excuse\n",
            "\u001b[31m<PERSON_2>\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print_colored_pii(anonymizer.anonymize(document_content2, language=\"fr\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3j1MB1EmMe0",
        "outputId": "f0de1d87-72f4-48b1-ea48-53907e4d149b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:Entity MISC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voici mon ID polonais : CBM708280 Mon numéro de sécurité sociale :191621398394290je suis Noah Rhodes \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(anonymizer.deanonymizer_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5mgT20uVSJl",
        "outputId": "c0130daa-5e18-47dc-f86e-1fde67a2656d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'POLISH_ID': {'<POLISH_ID>': 'ABC123456'}, 'NIR': {'<NIR>': ' 201069935115371 '}, 'US_BANK_NUMBER': {'QTAR38637940265423': '201069935115371'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-cohere\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL3QXnhDXA1Y",
        "outputId": "0c4004da-c742-43a9-fe74-f732f19ec2cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-cohere\n",
            "  Downloading langchain_cohere-0.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere)\n",
            "  Downloading cohere-5.8.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-core<0.3,>=0.2.24 (from langchain-cohere)\n",
            "  Downloading langchain_core-0.2.29-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-experimental>=0.0.6 (from langchain-cohere)\n",
            "  Downloading langchain_experimental-0.0.64-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (2.0.3)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.9.0)\n",
            "Collecting boto3<2.0.0,>=1.34.0 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading boto3-1.34.158-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx>=0.21.2 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.20.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.24->langchain-cohere) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.2.24->langchain-cohere)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3,>=0.2.24->langchain-cohere)\n",
            "  Downloading langsmith-0.1.99-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.24->langchain-cohere) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.24->langchain-cohere) (8.5.0)\n",
            "Collecting langchain-community<0.3.0,>=0.2.10 (from langchain-experimental>=0.0.6->langchain-cohere)\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (1.25.2)\n",
            "Collecting botocore<1.35.0,>=1.34.158 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading botocore-1.34.158-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.24->langchain-cohere)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.12 (from langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere)\n",
            "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-cohere)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.23.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.4)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.12->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (3.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.2.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_cohere-0.2.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.8.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.2.29-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.0.64-py3-none-any.whl (204 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.34.158-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.99-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Downloading botocore-1.34.158-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: types-requests, parameterized, orjson, mypy-extensions, marshmallow, jsonpointer, jmespath, httpx-sse, h11, fastavro, typing-inspect, jsonpatch, httpcore, botocore, s3transfer, langsmith, httpx, dataclasses-json, langchain-core, boto3, langchain-text-splitters, cohere, langchain, langchain-community, langchain-experimental, langchain-cohere\n",
            "Successfully installed boto3-1.34.158 botocore-1.34.158 cohere-5.8.0 dataclasses-json-0.6.7 fastavro-1.9.5 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.12 langchain-cohere-0.2.0 langchain-community-0.2.11 langchain-core-0.2.29 langchain-experimental-0.0.64 langchain-text-splitters-0.2.2 langsmith-0.1.99 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.7 parameterized-0.9.0 s3transfer-0.10.2 types-requests-2.32.0.20240712 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install -U langchain-cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ylht61OeLAw",
        "outputId": "2700e9ea-945b-497b-b205-03b22d09ec8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Requirement already satisfied: langchain-cohere in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5.6 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (5.8.0)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.24 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.2.29)\n",
            "Requirement already satisfied: langchain-experimental>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.0.64)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (2.0.3)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.34.158)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (1.9.5)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.20.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.0.20240712)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.24->langchain-cohere) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.24->langchain-cohere) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.24->langchain-cohere) (0.1.99)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.24->langchain-cohere) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.24->langchain-cohere) (8.5.0)\n",
            "Requirement already satisfied: langchain-community<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain-experimental>=0.0.6->langchain-cohere) (0.2.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere) (1.25.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.158 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.34.158)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere) (0.10.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.24->langchain-cohere) (3.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (0.2.12)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.24->langchain-cohere) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.23.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.4)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (0.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (3.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.2.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain-experimental>=0.0.6->langchain-cohere) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# loading the API Keys (Cohere, Pinecone) from .env\n",
        "load_dotenv(find_dotenv(), override=True)\n",
        "\n",
        "COHERE_API_KEY = os.environ.get('COHERE_API_KEY')\n",
        "print(COHERE_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "T85wdEgLd5x_",
        "outputId": "edc75b3f-0798-4552-8917-3f54eff215ca"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dotenv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-b81e76230a57>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_dotenv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# loading the API Keys (Cohere, Pinecone) from .env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_dotenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-chroma bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rltrp4vu680",
        "outputId": "acb9ff3e-0196-4d2e-cb36-d61adba01f78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.7/427.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl8wfaVfxFNE",
        "outputId": "47594fc5-1e01-40af-bc2a-c19a634709bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [Document(page_content=document_content2)]\n",
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dOSLAtc0t_q",
        "outputId": "f085a4e3-8ed2-4fc8-8b0c-475def568716"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content=\"Je suis Marine Hugo j'ai 23 ans et j'habite à marseille\")]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm = ChatCohere(model=\"command-r\",cohere_api_key=COHERE_API_KEY)"
      ],
      "metadata": {
        "id": "bItI7bxtvYpx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import CohereEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader\n",
        "# Load, chunk and index the contents of the blog.\n",
        "\n",
        "loader = TextLoader(file_path=\"/content/marine.txt\")\n",
        "docs = loader.load()\n",
        "print(docs)\n",
        "for doc in docs:\n",
        "    doc.page_content = anonymizer.anonymize(doc.page_content)\n",
        "print(docs)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "print(\"text splitter\",text_splitter)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "print(splits)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=CohereEmbeddings(user_agent=\"langchain\"))\n",
        "\n",
        "# Retrieve and generate using the relevant snippets of the blog.\n",
        "retriever = vectorstore.as_retriever()\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_F9MXmXvcDX",
        "outputId": "28a7c44d-0505-4b55-a963-cc08457dfb7d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': '/content/marine.txt'}, page_content=\"Je suis Marine Hugo j'ai 23 ans et j'habite à marseille\")]\n",
            "[Document(metadata={'source': '/content/marine.txt'}, page_content=\"Je suis <PERSON> j'ai 23 ans et j'habite à <LOCATION>\")]\n",
            "text splitter <langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x78175ee0bfd0>\n",
            "[Document(metadata={'source': '/content/marine.txt'}, page_content=\"Je suis <PERSON> j'ai 23 ans et j'habite à <LOCATION>\")]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
            "Please use the `langsmith sdk` instead:\n",
            "  pip install langsmith\n",
            "Use the `pull_prompt` method.\n",
            "  res_dict = client.pull_repo(owner_repo_commit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"ou habite marine ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "0z9XlH3dvemW",
        "outputId": "52ea78d5-b1aa-478e-a3d4-e4b3a501013a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'La personne dont on parle habite à <LOCATION>.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleanup\n",
        "vectorstore.delete_collection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eee1UEx8vgn2",
        "outputId": "d6c251c5-d011-4c9b-cbfc-a2fcb32e0ea8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkQuYskqCjHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anonymiser le prompt :"
      ],
      "metadata": {
        "id": "6orX70hNCk48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain_cohere import ChatCohere\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import (\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "\n",
        "# 6. Create anonymizer chain\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {anonymized_question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model = ChatCohere(model=\"command-r\",cohere_api_key=COHERE_API_KEY)\n",
        "\n",
        "\n",
        "\n",
        "_inputs = RunnableParallel(\n",
        "    question=RunnablePassthrough(),\n",
        "    # It is important to remember about question anonymization\n",
        "    anonymized_question=RunnableLambda(anonymizer.anonymize),\n",
        ")\n",
        "\n",
        "anonymizer_chain = (\n",
        "    _inputs\n",
        "    | {\n",
        "        \"context\": itemgetter(\"anonymized_question\") | retriever,\n",
        "        \"anonymized_question\": itemgetter(\"anonymized_question\"),\n",
        "    }\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyTdktHuCkMq",
        "outputId": "a2e6cac9-2211-4f98-cf7f-bf19b7f35ee8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anonymizer_chain.invoke(\n",
        "    \"Elle habite où marine ??\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "frLsp_xTDri4",
        "outputId": "4bdeeb77-4a32-4887-a58f-0f628e5379ff"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Marine habite à <LOCATION>, selon le texte. Malheureusement, je ne peux pas vous dire quel est cet endroit car le document fourni ne l'indique pas.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Add deanonymization step to the chain\n",
        "chain_with_deanonymization = anonymizer_chain | RunnableLambda(anonymizer.deanonymize)\n",
        "\n",
        "print(\n",
        "    chain_with_deanonymization.invoke(\n",
        "        \"Elle habite où marine ?\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV4GCDczEQPj",
        "outputId": "8e3a4b95-ad9c-4571-a938-44f39a4cc059"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marine habite à marseille, selon le texte. Malheureusement, le document ne fournit pas d'informations supplémentaires sur l'endroit exact où elle vit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_with_deanonymization.invoke(\"Whose phone number is it: 999-888-7777?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSZWHdzbEjqS",
        "outputId": "4068ccca-9066-4391-8621-561b64a4a508"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, I couldn't find any information about whose phone number it is, based only on the given context. The text provided only mentions one person, who is referred to as Marine Hugo. This person is 23 years old and lives in marseille, but no phone number is mentioned.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_model_construction.py:268: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}